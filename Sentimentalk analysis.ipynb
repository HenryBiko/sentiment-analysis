{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PDS 7.1 Activity 2 Final",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDE8u6_hMPnY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3f2c833c-11d8-4411-cf12-f6f0feca5ee8"
      },
      "source": [
        "# Run code below to download packages\n",
        "!pip install regex\n",
        "!pip install nltk\n",
        "\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"stopwords\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS7RcPBKgN3Z"
      },
      "source": [
        "# Movie reviews to test NLP pipeline for: The Imitation Game (2014)\n",
        "# Reviews taken from\n",
        "# https://www.rottentomatoes.com/m/the_imitation_game\n",
        "\n",
        "orig_text = \"\"\"This film about one of the past century's smartest humans at times treats its own audience like a classroom of remedial learners.\n",
        "The only reason I can surmise for the positive reviews The Imitation Game is that it confirms all the \"normal\" audience's worst suspicions about \"genius\" and queer life, without offering any meaningful insight into either.\n",
        "To be honest, I'm a bit surprised that there hasn't been more pushback against The Imitation Game by intelligence professionals, historians, and survivors of Turing's circle.\n",
        "An agonisingly shallow, de-historical depiction of Turing as psychological agent.\n",
        "Hollywood biopics infantilizes its audiences. If someone's true story ended badly, it's a text epilogue that tells us what happened. When Hollywood does another biopic of Jesus's life they will leave out the crucifixion.\n",
        "One of the film's achievements comes from hinting at the enormous power possessed by an unseen monarch...\n",
        "Though hindsight is always 20/20, The Imitation Game gives us a fair and balanced glance at the tragedies that prejudice and inequality can cause. Turing achieved more in one war-torn decade than Bill Gates or Steve Jobs.\n",
        "It is watchable and entertaining but more importantly it's a movie that reveals to the world a man who's achievements many more should celebrate.\n",
        "The Imitation Game is a film that will in all likelihood earn Benedict Cumberbatch his first Oscar nomination, for he absolutely shines as Alan Turing in this top-notch biopic.\n",
        "Graham Moore's screenplay has the right mix of political tension with some surprising humor sprinkled in.\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o13qVr3uPD7m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "8a3d653d-bed7-4dcf-b240-05c8c1930e44"
      },
      "source": [
        "# Change new line split to and split each review as its own item in the overall list of reviews\n",
        "split_text = orig_text.split(\"\\n\")\n",
        "split_text = [split_text.replace('\\n',' ') for split_text in split_text]\n",
        "split_text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"This film about one of the past century's smartest humans at times treats its own audience like a classroom of remedial learners.\",\n",
              " 'The only reason I can surmise for the positive reviews The Imitation Game is that it confirms all the \"normal\" audience\\'s worst suspicions about \"genius\" and queer life, without offering any meaningful insight into either.',\n",
              " \"To be honest, I'm a bit surprised that there hasn't been more pushback against The Imitation Game by intelligence professionals, historians, and survivors of Turing's circle.\",\n",
              " 'An agonisingly shallow, de-historical depiction of Turing as psychological agent.',\n",
              " \"Hollywood biopics infantilizes its audiences. If someone's true story ended badly, it's a text epilogue that tells us what happened. When Hollywood does another biopic of Jesus's life they will leave out the crucifixion.\",\n",
              " \"One of the film's achievements comes from hinting at the enormous power possessed by an unseen monarch...\",\n",
              " 'Though hindsight is always 20/20, The Imitation Game gives us a fair and balanced glance at the tragedies that prejudice and inequality can cause. Turing achieved more in one war-torn decade than Bill Gates or Steve Jobs.',\n",
              " \"It is watchable and entertaining but more importantly it's a movie that reveals to the world a man who's achievements many more should celebrate.\",\n",
              " 'The Imitation Game is a film that will in all likelihood earn Benedict Cumberbatch his first Oscar nomination, for he absolutely shines as Alan Turing in this top-notch biopic.',\n",
              " \"Graham Moore's screenplay has the right mix of political tension with some surprising humor sprinkled in.\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHZh6rcqIuNs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d676b252-1822-4073-98d9-46e06b924a14"
      },
      "source": [
        "# For easy accuracy testing, create a list of the labels in order\n",
        "split_text_labels = []\n",
        "[split_text_labels.append('negative') for i in range(5)]\n",
        "[split_text_labels.append('positive') for i in range(5)]\n",
        "\n",
        "split_text_labels"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'negative',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive',\n",
              " 'positive']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AodfYxxgOaGN"
      },
      "source": [
        "def pre_processing(text):\n",
        "\n",
        "    return cleaned_text\n",
        "\n",
        "def train_model(training_data):\n",
        "\n",
        "    return classifier\n",
        "\n",
        "def sentiment_analysis(classifier, cleaned_text):\n",
        "    \n",
        "    return score\n",
        "\n",
        "def nlp_pipeline(text):\n",
        "    pp = pre_process(text)\n",
        "\n",
        "    lm = train_model(csv_link)\n",
        "\n",
        "    snt = sentiment_analysis(lm, pp)\n",
        "    \n",
        "    return snt\n",
        "\n",
        "nlp_pipeline(split_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsdwYo_TNPRA"
      },
      "source": [
        "Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRgg8Qp_MEiC"
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import pandas as pd\n",
        "import nltk\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.classify import NaiveBayesClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6ugQw32SGnH"
      },
      "source": [
        "def pre_process(text):\n",
        "    \"\"\"This function takes a ***list*** of movie reviews and pre-processes it with these steps:\n",
        "    remove capitalization, \n",
        "    remove numbers,\n",
        "    remove punctuation,\n",
        "    remove whitespace, \n",
        "    remove stop words.\n",
        "\n",
        "    Note: Input text must be a list of strings.\n",
        "    \"\"\"\n",
        "        \n",
        "    # Lowercase\n",
        "    reviews = [text.lower() for text in text]\n",
        "\n",
        "    # Remove numbers\n",
        "    # I chose to use regular expression here\n",
        "    reviews = [re.sub(r'\\d+', '', text) for text in reviews]\n",
        "\n",
        "    # Remove punctuation\n",
        "    # I chose to use regular expression here again\n",
        "    reviews = [re.sub(r'[^\\w\\s]', '', text) for text in reviews]\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    reviews = [text.strip() for text in reviews]\n",
        "\n",
        "    # Remove stopwords\n",
        "    # Remember to download the package with this code before importing\n",
        "    # nltk.download(\"stopwords\")\n",
        "    # from nltk.corpus import stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # Note: to remove stopwords,\n",
        "    # you must \"tokenize\" or \"_string_.split\" each sentence\n",
        "    # if you tokenize, run nltk.download(\"punkt\") \n",
        "    # then use word_tokenize(text)\n",
        "\n",
        "    cleaned_reviews = []\n",
        "    for review in reviews:\n",
        "        tokens = [word for word in word_tokenize(review) if not word in stop_words]\n",
        "        cleaned_reviews.append(\" \".join(tokens))\n",
        "        \n",
        "    # Lemmatize\n",
        "    # We choose the porterstemmer because it's the fastest computationally\n",
        "    # and has less chance of overfitting\n",
        "    # from nltk.stem import PorterStemmer\n",
        "    porter = PorterStemmer()\n",
        "    lem_reviews = []\n",
        "    for review in cleaned_reviews:\n",
        "        lem_reviews.append(\" \".join( list(map(porter.stem, word_tokenize(review))) ))\n",
        "\n",
        "    # Final pre-processed reviews\n",
        "    return lem_reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VjvlPlfgWBh"
      },
      "source": [
        "# Run your function here and verify with results below\n",
        "cleaned_text = pre_process(split_text)\n",
        "cleaned_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO_QlXutgRGi"
      },
      "source": [
        "This is how the output should look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQS1aTrtPq_B",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e45067e7-a396-40ac-dd24-9e71ebeaa950"
      },
      "source": [
        "# Do not run or delete this cell!!!\n",
        "pre_process(split_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['film one past centuri smartest human time treat audienc like classroom remedi learner',\n",
              " 'reason surmis posit review imit game confirm normal audienc worst suspicion geniu queer life without offer meaning insight either',\n",
              " 'honest im bit surpris hasnt pushback imit game intellig profession historian survivor ture circl',\n",
              " 'agonisingli shallow dehistor depict ture psycholog agent',\n",
              " 'hollywood biopic infantil audienc someon true stori end badli text epilogu tell us happen hollywood anoth biopic jesuss life leav crucifixion',\n",
              " 'one film achiev come hint enorm power possess unseen monarch',\n",
              " 'though hindsight alway imit game give us fair balanc glanc tragedi prejudic inequ caus ture achiev one wartorn decad bill gate steve job',\n",
              " 'watchabl entertain importantli movi reveal world man who achiev mani celebr',\n",
              " 'imit game film likelihood earn benedict cumberbatch first oscar nomin absolut shine alan ture topnotch biopic',\n",
              " 'graham moor screenplay right mix polit tension surpris humor sprinkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oBl2X7qd3oJ"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C4i7DEvkotZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "49ca9e2c-f530-48cb-9fe8-ab6b0fd04892"
      },
      "source": [
        "# Inspired from this website\n",
        "# https://www.pythonforengineers.com/build-a-sentiment-analysis-app-with-movie-reviews/\n",
        "\n",
        "# This is how the Naive Bayes classifier expects the input\n",
        "create_word_features = lambda words: dict([(word, True) for word in words])\n",
        "\n",
        "# Expected output\n",
        "create_word_features(cleaned_neg_reviews[0].split())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'could': True,\n",
              " 'four': True,\n",
              " 'genr': True,\n",
              " 'great': True,\n",
              " 'gritti': True,\n",
              " 'straddl': True,\n",
              " 'total': True,\n",
              " 'unfocus': True,\n",
              " 'werent': True}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ieb1z_Wd5ZT"
      },
      "source": [
        "# Note that len(rt_reviews) is 480000\n",
        "# so we are only working with a smaller n\n",
        "# number of data to train and test on\n",
        "n = int(10000/2)\n",
        "\n",
        "raw_csv = 'https://raw.githubusercontent.com/nathantorento/practical-data-science-tutorial/master/rotten_tomatoes_reviews.csv'\n",
        "rt_reviews = pd.read_csv(raw_csv)\n",
        "\n",
        "# Create a separate variable for negative reviews in a specific format\n",
        "# so that each review becomes a set: (create_word_features(), \"negative\")\n",
        "neg_reviews_raw = rt_reviews[rt_reviews['Freshness']==0].sample(n, random_state=123)\n",
        "neg_reviews_raw = neg_reviews_raw.iloc[:, 1]\n",
        "\n",
        "cleaned_neg_reviews = pre_process(neg_reviews_raw)\n",
        "\n",
        "neg_reviews = []\n",
        "for review in cleaned_neg_reviews:\n",
        "    neg_reviews.append((create_word_features(review.split()), \"negative\"))\n",
        "\n",
        "# Create a separate variable for positive reviews in a specific format\n",
        "# so that each review becomes a set: (create_word_features(), \"positive\")\n",
        "pos_reviews_raw = rt_reviews[rt_reviews['Freshness']==1].sample(n, random_state=123)\n",
        "pos_reviews_raw = pos_reviews_raw.iloc[:, 1]\n",
        "\n",
        "cleaned_pos_reviews = pre_process(pos_reviews_raw)\n",
        "\n",
        "pos_reviews = []\n",
        "for review in cleaned_pos_reviews:\n",
        "    pos_reviews.append((create_word_features(review.split()), \"positive\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGH9v3mefNSn"
      },
      "source": [
        "This is how one of the pos_reviews or neg_reviews output should look like.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2poe-in0eZ0u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "90bfe001-ab52-46cd-e71d-f74a1beee00e"
      },
      "source": [
        "# Do not run or delete this cell!!!\n",
        "pos_reviews[0:2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[({'chapter': True,\n",
              "   'charact': True,\n",
              "   'deconstruct': True,\n",
              "   'end': True,\n",
              "   'full': True,\n",
              "   'holm': True,\n",
              "   'last': True,\n",
              "   'live': True,\n",
              "   'reconstruct': True,\n",
              "   'review': True,\n",
              "   'sherlock': True,\n",
              "   'spanish': True},\n",
              "  'positive'),\n",
              " ({'art': True,\n",
              "   'boundarypush': True,\n",
              "   'breakthrough': True,\n",
              "   'career': True,\n",
              "   'debut': True,\n",
              "   'direct': True,\n",
              "   'freedsonjackson': True,\n",
              "   'new': True,\n",
              "   'perform': True,\n",
              "   'perhap': True,\n",
              "   'pettyf': True,\n",
              "   'radcliff': True,\n",
              "   'signal': True,\n",
              "   'wolkstein': True},\n",
              "  'positive')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqvYUqUKfHid",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "673c5abf-f7fc-4551-e677-55242360fe88"
      },
      "source": [
        "# Create a train and test set, both adding the appropriate subset size of neg_reviews + pos_reviews\n",
        "test_size = 0.2\n",
        "train_set = neg_reviews[:int(len(neg_reviews)*(1-test_size))] + pos_reviews[:int(len(neg_reviews)*(1-test_size))]\n",
        "test_set = neg_reviews[int(len(neg_reviews)*(1-test_size)):] + pos_reviews[int(len(neg_reviews)*(1-test_size)):]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8000 2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bwshNabed-d"
      },
      "source": [
        "# Create your classifier\n",
        "#from nltk.classify import NaiveBayesClassifier\n",
        "classifier = NaiveBayesClassifier.train(train_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7Z5FknJhar_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c91c534-a8bc-4715-cf0b-d5c5cd4bb471"
      },
      "source": [
        "# Feel free to check the accuracy of your current model\n",
        "accuracy = nltk.classify.util.accuracy(classifier, test_set)\n",
        "print(accuracy * 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "73.35000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlwAZvnmFwV0"
      },
      "source": [
        "def train_model(csv_link):\n",
        "    create_word_features = lambda words: dict([(word, True) for word in words])\n",
        "\n",
        "    n = int(10000/2)\n",
        "\n",
        "    rt_reviews = pd.read_csv(csv_link)\n",
        "\n",
        "    # Create a separate variable for negative reviews in a specific format\n",
        "    # so that each review becomes a set: (create_word_features(), \"negative\")\n",
        "    neg_reviews_raw = rt_reviews[rt_reviews['Freshness']==0].sample(n, random_state=123)\n",
        "    neg_reviews_raw = neg_reviews_raw.iloc[:, 1]\n",
        "\n",
        "    cleaned_neg_reviews = pre_process(neg_reviews_raw)\n",
        "\n",
        "    neg_reviews = []\n",
        "    for review in cleaned_neg_reviews:\n",
        "        neg_reviews.append((create_word_features(review.split()), \"negative\"))\n",
        "\n",
        "    # Create a separate variable for positive reviews in a specific format\n",
        "    # so that each review becomes a set: (create_word_features(), \"positive\")\n",
        "    pos_reviews_raw = rt_reviews[rt_reviews['Freshness']==1].sample(n, random_state=123)\n",
        "    pos_reviews_raw = pos_reviews_raw.iloc[:, 1]\n",
        "\n",
        "    cleaned_pos_reviews = pre_process(pos_reviews_raw)\n",
        "\n",
        "    pos_reviews = []\n",
        "    for review in cleaned_pos_reviews:\n",
        "        pos_reviews.append((create_word_features(review.split()), \"positive\"))\n",
        "\n",
        "    test_size = 0.2\n",
        "    train_set = neg_reviews[:int(len(neg_reviews)*(1-test_size))] + pos_reviews[:int(len(neg_reviews)*(1-test_size))]\n",
        "    test_set = neg_reviews[int(len(neg_reviews)*(1-test_size)):] + pos_reviews[int(len(neg_reviews)*(1-test_size)):]\n",
        "\n",
        "    classifier = NaiveBayesClassifier.train(train_set)\n",
        "    \n",
        "    return classifier #Output is trained model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7BOB6roG0Gj"
      },
      "source": [
        "classifier = train_model('https://raw.githubusercontent.com/nathantorento/practical-data-science-tutorial/master/rotten_tomatoes_reviews.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pM7TpS_QtIY"
      },
      "source": [
        "This is how the output should look like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgvhZTlWQolU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52bb07e4-07fd-49b3-f0ed-fba97cfb5d8f"
      },
      "source": [
        "classifier"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<nltk.classify.naivebayes.NaiveBayesClassifier at 0x7fe5f3d745c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 195
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMb7QqSjXpmT"
      },
      "source": [
        "Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evapxY-nHiLE"
      },
      "source": [
        "def sentiment_analysis(classifier, cleaned_text):\n",
        "    # Test accuracy\n",
        "    # Convert our original lemmatized reviews into the necessary format\n",
        "    # to test the classifier\n",
        "    score = []\n",
        "    for i, review in enumerate(cleaned_text):\n",
        "        score.append(split_text_labels[i] == classifier.classify(review))\n",
        "    \n",
        "    return f\"{sum(score)}/10\", score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxnE6ztpPUsb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d32cb3a-523a-43fe-c42b-69dd63fbd9db"
      },
      "source": [
        "sentiment_analysis(classifier, cleaned_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('8/10', [False, True, False, True, True, True, True, True, True, True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdukTjZYPg2k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa1a9d38-90b7-4663-e6e3-9940d2365aa4"
      },
      "source": [
        "def nlp_pipeline(text):\n",
        "    pp = pre_process(text)\n",
        "\n",
        "    lm = train_model('https://raw.githubusercontent.com/nathantorento/practical-data-science-tutorial/master/rotten_tomatoes_reviews.csv')\n",
        "\n",
        "    snt = sentiment_analysis(lm, pp)\n",
        "    \n",
        "    return snt\n",
        "\n",
        "nlp_pipeline(split_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('8/10', [False, True, False, True, True, True, True, True, True, True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    }
  ]
}